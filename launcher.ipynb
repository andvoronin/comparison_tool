{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from comparisonHelper import TestParamsReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_file_path = os.path.join(os.getcwd(), \"results\")\n",
    "os.makedirs(master_file_path,exist_ok=True)\n",
    "param_file_name = os.path.join(os.getcwd(), \"params.json\")\n",
    "\n",
    "src_path = os.path.join(os.getcwd(), 'src.csv')\n",
    "tgt_path = os.path.join(os.getcwd(), 'tgt.csv')\n",
    "runner_results_path = os.path.join(os.getcwd(), 'runner_result.json')\n",
    "\n",
    "print('Reading testing configs...')\n",
    "config_reader = TestParamsReader()\n",
    "all_configs = config_reader.all_configs\n",
    "total_tests = len(all_configs)\n",
    "passed_tests = 0\n",
    "skipped_tests = 0\n",
    "test_results = []\n",
    "if all_configs:\n",
    "    print(f'Running {total_tests} tests...')\n",
    "    index = 1\n",
    "    for test in all_configs:\n",
    "        print(f'Running {index}/{total_tests} {test.name}...', end=' ')\n",
    "        test_result = {'name': test.name}\n",
    "        if not test.get_description_errors():\n",
    "            test.source_config.save_to_csv(src_path)\n",
    "            test.target_config.save_to_csv(tgt_path)\n",
    "            # prepare config file\n",
    "            settings_for_config = {}\n",
    "            settings_for_config['name'] = test.name\n",
    "            settings_for_config['source_path'] = src_path\n",
    "            settings_for_config['target_path'] = tgt_path\n",
    "            settings_for_config['column_mapping'] = test.column_mapping\n",
    "            with open(param_file_name, 'w') as f:\n",
    "                json.dump(settings_for_config, f)\n",
    "            %run comparison_runner.ipynb\n",
    "            # read result\n",
    "            with open(runner_results_path, 'r') as f:\n",
    "                results = json.load(f)\n",
    "                result_status = results['status']\n",
    "                print(result_status)\n",
    "                test_result['status'] = result_status\n",
    "                if result_status == 'Passed':\n",
    "                    passed_tests+=1\n",
    "        else:\n",
    "            print('Skipped: ' + '\\n'.join(test.get_description_errors()))\n",
    "            test_result['status'] = 'Skipped'\n",
    "            skipped_tests+=1\n",
    "        test_results.append(test_result)\n",
    "        index+=1\n",
    "    failed_tests = total_tests - passed_tests - skipped_tests\n",
    "    print(f'Completed: {passed_tests} passed, {failed_tests} failed, {skipped_tests} skipped')\n",
    "else:\n",
    "    print(f'0 tests found, nothing to run')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b0c1fcbb24b15d76e15de7eab5bb07c92564d7b99a636f63d6f23b6e60b67e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
