{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = datetime.now().strftime(\"%Y%m%d_%H%M%S%f\")\n",
    "runner_cache_folder = os.path.join(os.getcwd(),'runner_cache', runid)\n",
    "os.makedirs(runner_cache_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    Cheatsheet\n",
    "    Each value in the list represents single column used in comparison\n",
    "        - source_name: name of the column in the source csv file (usually file extracted from Power BI)\n",
    "        - target_name: name of the column in the target csv file (usually extracted from the Synapse query result)\n",
    "        - key: if True, will be used to join the extract, if False - column will be used for the comparison\n",
    "        - comparison: only applicable if key = False. Type of the comparison. Available options:\n",
    "            \"numeric\" - comparison based on subtraction of the columns\n",
    "            \"string\" - comparison bsed on theexact value of he column\n",
    "        - clean: only applicable if key = False and comparison = numeric. Removes spaces $ and % signs from the coluns in Power BI extract\n",
    "        - precision: only applicable if key = False and comparison = numeric. Sets how many digits after 0 should be considered as discrepancy\n",
    "        - negative_format: only applicable if key = False and comparison = numeric. if the value is \"parentheses\" then \n",
    "                the value in parentheses is replaced by the negative number, e.g. (156.23) -> -156.23. Useful for the data extracted from Power BI Desktop\n",
    "        - ignore_case : only applicable if key = False and comparison = string. Ignores letter case during comparison if set to True\n",
    "        - replace_nulls: only applicable if key = False. if set, then NULLs in the comparison columns are replaced by zeros.\n",
    "                available options: \n",
    "                    \"pbi\" - replace NULLs in Power BI extract only\n",
    "                    \"dm\" - replace NULLs in Data Mart extract (NaN and numpy inf both considered as NULLs)\n",
    "                    \"both\": replaces value in both extracts\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone_mode = False\n",
    "\n",
    "if standalone_mode:\n",
    "    # Set up the variables\n",
    "    test_name = \"comparison_shipping_history\"\n",
    "   # src_extract_path = r\"C:\\Users\\12000498\\Downloads\\shipping_efficency\\test_page_1.csv\" # path to file extracted from Power BI Desktop\n",
    "   # tgt_extract_path = r\"C:\\Users\\12000498\\Downloads\\shipping_efficency\\prod_page_1.csv\" # path to file extracted from the synapse query result\n",
    "   # columns = [\n",
    "   # {'source_name': 'Product Category', 'target_name': 'Product Category', 'key': True},\n",
    "   # {'source_name': 'Product Sub Category', 'target_name': 'Product Sub Category', 'key': True},\n",
    "   # {'source_name': 'Individual Unit Container', 'target_name': 'Individual Unit Container', 'key': True},\n",
    "   # {'source_name': 'Bottle Size', 'target_name': 'Bottle Size', 'key': True},\n",
    "   # {'source_name': 'Supply Area', 'target_name': 'Supply Area', 'key': True},\n",
    "   # {'source_name': 'Site Name', 'target_name': 'Site Name', 'key': True},\n",
    "   # {'source_name': 'Brand', 'target_name': 'Brand', 'key': True},\n",
    "   # {'source_name': 'Year', 'target_name': 'Year', 'key': True},\n",
    "   # {'source_name': 'Month', 'target_name': 'Month', 'key': True},\n",
    "#\n",
    "   # {'source_name': 'Efficient Ship','target_name': 'Efficient Ship', 'key': False, 'comparison': 'numeric', 'clean': False, 'replace_nulls': 'both', 'precision': 0},\n",
    "   # {'source_name': 'Non-Efficient Ship','target_name': 'Non-Efficient Ship', 'key': False, 'comparison': 'numeric', 'clean': False ,'replace_nulls': 'both', 'precision': 0},\n",
    "   # {'source_name': 'Efficient Ship %','target_name': 'Efficient Ship %', 'key': False, 'comparison': 'numeric', 'clean': 'both', 'replace_nulls': 'both', 'precision': 3}\n",
    "   # ]\n",
    "\n",
    "   # src_extract_path = r\"C:\\Users\\12000498\\Downloads\\shipping_efficency\\test_page_2.csv\" # path to file extracted from Power BI Desktop\n",
    "   # tgt_extract_path = r\"C:\\Users\\12000498\\Downloads\\shipping_efficency\\prod_page_2.csv\" # path to file extracted from the synapse query result\n",
    "   # columns = [\n",
    "   # {'source_name': 'Channel', 'target_name': 'Channel', 'key': True},\n",
    "   # {'source_name': 'level_3_sap_company_name', 'target_name': 'level_3_sap_company_name', 'key': True},\n",
    "   # {'source_name': 'Year', 'target_name': 'Year', 'key': True},\n",
    "   # {'source_name': 'Month', 'target_name': 'Month', 'key': True},\n",
    " #\n",
    " \n",
    "   # {'source_name': 'Efficient Ship','target_name': 'Efficient Ship', 'key': False, 'comparison': 'numeric', 'clean': False, 'replace_nulls': 'both', 'precision': 0},\n",
    "   # {'source_name': 'Non-Efficient Ship','target_name': 'Non-Efficient Ship', 'key': False, 'comparison': 'numeric', 'clean': False ,'replace_nulls': 'both', 'precision': 0},\n",
    "   # {'source_name': 'Efficient Ship %','target_name': 'Efficient Ship %', 'key': False, 'comparison': 'numeric', 'clean': 'both', 'replace_nulls': 'both', 'precision': 3}\n",
    "   # ]\n",
    "    src_extract_path = r\"C:\\Users\\12000498\\Downloads\\shipping_efficency\\test_page_3_2023.csv\" # path to file extracted from Power BI Desktop\n",
    "    tgt_extract_path = r\"C:\\Users\\12000498\\Downloads\\shipping_efficency\\prod_page_3_2023.csv\" # path to file extracted from the synapse query result\n",
    "    columns = [\n",
    "    {'source_name': 'Origin Supply Area', 'target_name': 'Origin Supply Area', 'key': True},\n",
    "    {'source_name': 'Origin Plant', 'target_name': 'Origin Plant', 'key': True},\n",
    "    {'source_name': 'Prod Plant', 'target_name': 'Prod Plant', 'key': True},\n",
    "    {'source_name': 'Bottle Size', 'target_name': 'Bottle Size', 'key': True},\n",
    "    {'source_name': 'Material', 'target_name': 'Material', 'key': True},\n",
    "    {'source_name': 'Material Name', 'target_name': 'Material Name', 'key': True},\n",
    "\n",
    "    {'source_name': 'CE','target_name': 'CE', 'key': False, 'comparison': 'numeric', 'clean': 'both', 'replace_nulls': 'both', 'precision': 0},\n",
    "    {'source_name': '% of Total','target_name': '% of Total', 'key': False, 'comparison': 'numeric', 'clean': 'both' ,'replace_nulls': 'both', 'precision': 3}\n",
    "    ]\n",
    "else:\n",
    "    # read setting from config\n",
    "    target_param_file = os.path.join(runner_cache_folder, \"params.json\")\n",
    "    shutil.copyfile(\"params.json\", target_param_file)\n",
    "    with open(target_param_file, \"r\") as f: \n",
    "        params = json.load(f)\n",
    "    src_extract_path = params[\"source_path\"]\n",
    "    tgt_extract_path = params[\"target_path\"]\n",
    "    columns = params[\"column_mapping\"]\n",
    "    test_name = params[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy csvs to the cache folder\n",
    "cache_src_file = os.path.join(runner_cache_folder, 'src.csv')\n",
    "cache_tgt_file = os.path.join(runner_cache_folder, 'tgt.csv')\n",
    "comparison_file = os.path.join(runner_cache_folder, 'comparison.csv')\n",
    "discrepancy_file = os.path.join(runner_cache_folder, 'discrep.csv')\n",
    "results_file = os.path.join(runner_cache_folder, 'result.json')\n",
    "\n",
    "shutil.copyfile(src_extract_path, cache_src_file)\n",
    "shutil.copyfile(tgt_extract_path, cache_tgt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for columns \n",
    "src_key_col_names = [column_def[\"source_name\"] for column_def in columns if column_def[\"key\"]]\n",
    "tgt_key_col_names = [column_def[\"target_name\"] for column_def in columns if column_def[\"key\"]]\n",
    "comparison_columns = [column_def for column_def in columns if (not column_def[\"key\"] and \"comparison\" in column_def)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source extract to df\n",
    "df_src = pd.read_csv(cache_src_file)\n",
    "rename_mapping = dict([[col[\"source_name\"], col[\"target_name\"]] for col in columns])\n",
    "# rename columns in source  extract so they match target extract\n",
    "df_src.rename(columns=rename_mapping, inplace=True)\n",
    "# delete undefined columns\n",
    "columns_to_drop = set(df_src.columns) - set(rename_mapping.values())\n",
    "df_src.drop(columns_to_drop, axis=1, inplace=True)\n",
    "# convert key columns to upper index\n",
    "for column_name in tgt_key_col_names:\n",
    "    if df_src[column_name].dtype == object:\n",
    "        df_src[column_name] = df_src[column_name].str.upper()\n",
    "# set index\n",
    "df_src.set_index(tgt_key_col_names, inplace=True)\n",
    "\n",
    "\n",
    "# load target extract to df\n",
    "df_tgt = pd.read_csv(cache_tgt_file)\n",
    "# convert key columns to upper index\n",
    "for column_name in tgt_key_col_names:\n",
    "    if df_tgt[column_name].dtype == object:\n",
    "        df_tgt[column_name] = df_tgt[column_name].str.upper()\n",
    "# set index\n",
    "df_tgt.set_index(tgt_key_col_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change format for negative numbers\n",
    "columns_to_update_format = [[column_def[\"target_name\"], column_def[\"negative_format\"]] for column_def in comparison_columns\n",
    "    if column_def[\"comparison\"] == 'numeric' and \"negative_format\" in column_def #and column_def[\"negative_format\"] == 'parentheses'\n",
    "    ]\n",
    "for column, negative_format_settings in columns_to_update_format:\n",
    "    if negative_format_settings['type'] == 'parentheses':\n",
    "        negative_format_value = negative_format_settings['value']\n",
    "        if negative_format_value == 'source' or negative_format_value == 'both':\n",
    "            df_src[column] = df_src[column].map(\n",
    "            lambda x : str(x)\n",
    "                    .replace(\"(\",\"-\")\n",
    "                    .replace(\")\",\"\")\n",
    "            )\n",
    "        if negative_format_value == 'target' or negative_format_value == 'both':\n",
    "            df_tgt[column] = df_tgt[column].map(\n",
    "            lambda x : str(x)\n",
    "                    .replace(\"(\",\"-\")\n",
    "                    .replace(\")\",\"\")\n",
    "            )\n",
    "\n",
    "# clean the data if needed\n",
    "columns_to_clean = [[column_def[\"target_name\"], column_def[\"clean\"]] for column_def in comparison_columns \n",
    "    if column_def[\"comparison\"] == 'numeric' and \"clean\" in column_def and column_def[\"clean\"]\n",
    "    ]\n",
    "# remove spaces, $ and % signs if exists\n",
    "for column_name, clean in columns_to_clean:\n",
    "    # source\n",
    "    if clean == 'source' or clean == 'both':\n",
    "        if df_src[column_name].dtype == object:\n",
    "            df_src[column_name] = df_src[column_name].map(\n",
    "                lambda x : str(x).replace(\"$\", \"\")\n",
    "                    .replace(\"%\", \"\")\n",
    "                    .replace(\" \",\"\")\n",
    "                    ).astype(np.float64)\n",
    "    \n",
    "    if clean == 'target' or clean == 'both':\n",
    "        if df_tgt[column_name].dtype == object:\n",
    "            df_tgt[column_name] = df_tgt[column_name].map(\n",
    "                lambda x : str(x).replace(\"$\", \"\")\n",
    "                    .replace(\"%\", \"\")\n",
    "                    .replace(\" \",\"\")\n",
    "                    ).astype(np.float64)\n",
    "    \n",
    "\n",
    "# replace nulls with zeros in compared columns\n",
    "columns_to_replace = [[column_def[\"target_name\"], column_def[\"replace_nulls\"], column_def[\"comparison\"]] for column_def in comparison_columns \n",
    "    if \"replace_nulls\" in column_def # column_def[\"comparison\"] == 'numeric' and\n",
    "    ]\n",
    "for column_name, replace_nulls, comparison_type in columns_to_replace:\n",
    "    replacement_value = 0 if comparison_type=='numeric' else ''\n",
    "    if replace_nulls == 'source' or replace_nulls == 'both': \n",
    "        df_src[column_name] = df_src[column_name].fillna(replacement_value).replace(np.inf, replacement_value)\n",
    "    if replace_nulls == 'target' or replace_nulls == 'both': \n",
    "        df_tgt[column_name] = df_tgt[column_name].fillna(replacement_value).replace(np.inf, replacement_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join into single dataframe\n",
    "comparison_df = df_src.join(df_tgt\n",
    "    , how=\"outer\", lsuffix='_src', rsuffix='_tgt')\n",
    "comparison_df[\"discrepancy\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare values\n",
    "\n",
    "# numeric comparison\n",
    "# subtract values in column\n",
    "numeric_columns = [col for col in comparison_columns if col['comparison']=='numeric']\n",
    "for comparison_column in numeric_columns:\n",
    "    column_name =  comparison_column[\"target_name\"]\n",
    "    target_col_name = f'{column_name}_diff'\n",
    "    comparison_df[target_col_name] = comparison_df[f\"{column_name}_src\"] - comparison_df[f\"{column_name}_tgt\"]\n",
    "    comparison_precision = comparison_column.get(\"precision\", 0)\n",
    "    comparison_df[\"discrepancy\"] = comparison_df[\"discrepancy\"] | (comparison_df[target_col_name].map(lambda x: abs(x)) >= 0.1**comparison_precision)\n",
    "    comparison_df[\"discrepancy\"] = comparison_df[\"discrepancy\"] | comparison_df[f\"{column_name}_src\"].isna() | comparison_df[f\"{column_name}_tgt\"].isna()\n",
    "    \n",
    "# string comparison\n",
    "\n",
    "string_columns = [col for col in comparison_columns if col['comparison']=='string']\n",
    "if string_columns:\n",
    "    # create column to save list of columns that are not matching\n",
    "    comparison_df['string_comparison_diff'] = \"\"\n",
    "    for comparison_column in string_columns:\n",
    "        column_name =  comparison_column[\"target_name\"]\n",
    "\n",
    "        if 'ignore_case' in comparison_column and comparison_column['ignore_case']:\n",
    "            comparison_df.loc[comparison_df[f'{column_name}_src'].str.lower() != comparison_df[f'{column_name}_tgt'].str.lower(), 'string_comparison_diff'] = \\\n",
    "                comparison_df.loc[comparison_df[f'{column_name}_src'].str.lower() != comparison_df[f'{column_name}_tgt'].str.lower(), 'string_comparison_diff'] + ' ' + column_name\n",
    "        else:\n",
    "            comparison_df.loc[comparison_df[f'{column_name}_src'] != comparison_df[f'{column_name}_tgt'], 'string_comparison_diff'] = \\\n",
    "                comparison_df.loc[comparison_df[f'{column_name}_src'] != comparison_df[f'{column_name}_tgt'], 'string_comparison_diff'] + ' ' + column_name\n",
    "\n",
    "    # write result\n",
    "    comparison_df.loc[comparison_df['string_comparison_diff']!='','discrepancy'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show records that doesn't match\n",
    "result  = comparison_df[comparison_df[\"discrepancy\"]]\n",
    "result_description = dict()\n",
    "result_description['cache_folder'] = runner_cache_folder\n",
    "if len(result) > 0:\n",
    "    result_description[\"status\"] = \"Failed\"\n",
    "    result_description[\"discrepancy_file\"] = discrepancy_file\n",
    "    result.to_csv(discrepancy_file)\n",
    "else:\n",
    "    result_description[\"status\"] = \"Passed\"\n",
    "\n",
    "# write execution details to json\n",
    "with open(results_file,\"w\") as f:\n",
    "    json.dump(result_description, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return path to the cache folder with the results of execution\n",
    "if not standalone_mode:\n",
    "    shutil.copyfile(results_file, \"runner_result.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b0c1fcbb24b15d76e15de7eab5bb07c92564d7b99a636f63d6f23b6e60b67e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
